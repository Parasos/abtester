{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c87709e4-2572-4867-adfb-355b0199d994",
   "metadata": {},
   "source": [
    "# abtester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd3c1e-c1b2-43a3-9a10-bf29cde7d099",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains the code snippets provided at the end of each calculation method of the web app. It is intended as a sandbox to play around with the functions, understand how they work, test and compare approaches and so on. Go ahead and have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82e9d5-7698-4a43-bdb5-cc5fe72bef0e",
   "metadata": {},
   "source": [
    "## Sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb5a5e-1076-4fc4-b8da-a620bbf69acf",
   "metadata": {},
   "source": [
    "### Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e52fa-a2e0-4784-8dc8-d5b492fe5f1b",
   "metadata": {},
   "source": [
    "#### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9448af9b-e6b5-4722-a24d-237272abf154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import math\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from statsmodels.stats.power import tt_ind_solve_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d0a477-6e76-47a1-8e68-7f5f410b84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "control_proportion = 0.15\n",
    "sensitivity = 0.1\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "power = 0.8\n",
    "control_ratio = 0.5\n",
    "treatment_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba834b8-297f-42bd-b28c-b29307ebb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample size\n",
    "if alternative == \"smaller\":\n",
    "    sensitivity *= -1\n",
    "treatment_proportion = control_proportion * (1 + sensitivity)\n",
    "effect_size = proportion_effectsize(\n",
    "    treatment_proportion,\n",
    "    control_proportion\n",
    ")\n",
    "alpha = 1 - confidence\n",
    "ratio = treatment_ratio / control_ratio\n",
    "control_sample = math.ceil(tt_ind_solve_power(\n",
    "    effect_size=effect_size,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    ratio=ratio,\n",
    "    alternative=alternative\n",
    "))\n",
    "treatment_sample = math.ceil(control_sample * ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db69724b-39dc-4c66-a785-93712221a457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size\n",
      "Control: 9,254\n",
      "Treatment: 9,254\n",
      "Total: 18,508\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "print(\"Sample size\")\n",
    "print(f\"Control: {control_sample:,}\")\n",
    "print(f\"Treatment: {treatment_sample:,}\")\n",
    "print(f\"Total: {(control_sample + treatment_sample):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30450d94-5c76-4121-a9f7-9b761b9fa411",
   "metadata": {},
   "source": [
    "#### Z-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60d1ef0-e02c-4e18-807a-443dcb0efeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import math\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from statsmodels.stats.power import zt_ind_solve_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db1af09-87dd-439c-8cba-53028c7db486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "control_proportion = 0.15\n",
    "sensitivity = 0.1\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "power = 0.8\n",
    "control_ratio = 0.5\n",
    "treatment_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46182f3b-e4e8-483a-85dd-7eff088e09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample size\n",
    "if alternative == \"smaller\":\n",
    "    sensitivity *= -1\n",
    "treatment_proportion = control_proportion * (1 + sensitivity)\n",
    "effect_size = proportion_effectsize(\n",
    "    treatment_proportion,\n",
    "    control_proportion\n",
    ")\n",
    "alpha = 1 - confidence\n",
    "ratio = treatment_ratio / control_ratio\n",
    "control_sample = math.ceil(zt_ind_solve_power(\n",
    "    effect_size=effect_size,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    ratio=ratio,\n",
    "    alternative=alternative\n",
    "))\n",
    "treatment_sample = math.ceil(control_sample * ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023c8596-1eed-44f1-bf0e-b3d22828c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size\n",
      "Control: 9,253\n",
      "Treatment: 9,253\n",
      "Total: 18,506\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "print(\"Sample size\")\n",
    "print(f\"Control: {control_sample:,}\")\n",
    "print(f\"Treatment: {treatment_sample:,}\")\n",
    "print(f\"Total: {(control_sample + treatment_sample):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f7e09-8b4b-418b-9de2-845989986a16",
   "metadata": {},
   "source": [
    "### Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5fc9a4-35f8-4060-9621-30218b0f6e04",
   "metadata": {},
   "source": [
    "#### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9c3154-b997-4759-be78-2017300e5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "from statsmodels.stats.power import tt_ind_solve_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47149390-4cba-416f-9ec4-c2eb7298f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"datasets/sample_size/dataset_a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98ef00e-95ba-4ef5-ad17-65e39d088cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "sensitivity = 0.1\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "power = 0.8\n",
    "control_ratio = 0.5\n",
    "treatment_ratio = 0.5\n",
    "control_mean = df[\"Measurement\"].mean()\n",
    "standard_deviation = df[\"Measurement\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0544feb-c65c-44d6-9ed8-604d2bfc4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample size\n",
    "if alternative == \"smaller\":\n",
    "    sensitivity *= -1\n",
    "treatment_mean = control_mean * (1 + sensitivity)\n",
    "difference = treatment_mean - control_mean\n",
    "effect_size = difference / standard_deviation\n",
    "alpha = 1 - confidence\n",
    "ratio = treatment_ratio / control_ratio\n",
    "control_sample = math.ceil(tt_ind_solve_power(\n",
    "    effect_size=effect_size,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    ratio=ratio,\n",
    "    alternative=alternative\n",
    "))\n",
    "treatment_sample = math.ceil(control_sample * ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0033c9-7362-4b22-9b8f-a5ecfe740e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size\n",
      "Control: 263\n",
      "Treatment: 263\n",
      "Total: 526\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "print(\"Sample size\")\n",
    "print(f\"Control: {control_sample:,}\")\n",
    "print(f\"Treatment: {treatment_sample:,}\")\n",
    "print(f\"Total: {(control_sample + treatment_sample):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb2f98-7508-428c-89be-7f95b091f552",
   "metadata": {},
   "source": [
    "#### Z-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "995788e4-c696-40ea-a033-fd016029dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "from statsmodels.stats.power import zt_ind_solve_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "140bbefa-c13c-4634-abd4-16d45e56ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"datasets/sample_size/dataset_a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60110eb8-75b3-4a3a-9b00-adf815bcd22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "sensitivity = 0.1\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "power = 0.8\n",
    "control_ratio = 0.5\n",
    "treatment_ratio = 0.5\n",
    "control_mean = df[\"Measurement\"].mean()\n",
    "standard_deviation = df[\"Measurement\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1ca4e4e-c71b-487c-9a09-01be98782c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample size\n",
    "if alternative == \"smaller\":\n",
    "    sensitivity *= -1\n",
    "treatment_mean = control_mean * (1 + sensitivity)\n",
    "difference = treatment_mean - control_mean\n",
    "effect_size = difference / standard_deviation\n",
    "alpha = 1 - confidence\n",
    "ratio = treatment_ratio / control_ratio\n",
    "control_sample = math.ceil(zt_ind_solve_power(\n",
    "    effect_size=effect_size,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    ratio=ratio,\n",
    "    alternative=alternative\n",
    "))\n",
    "treatment_sample = math.ceil(control_sample * ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "555ae9d9-77a3-4014-9864-441f6bf88f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size\n",
      "Control: 262\n",
      "Treatment: 262\n",
      "Total: 524\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "print(\"Sample size\")\n",
    "print(f\"Control: {control_sample:,}\")\n",
    "print(f\"Treatment: {treatment_sample:,}\")\n",
    "print(f\"Total: {(control_sample + treatment_sample):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc865163-eca5-450a-9051-525e2b966b0a",
   "metadata": {},
   "source": [
    "## Statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728bf71f-42c4-44bf-b354-cfb289e49922",
   "metadata": {},
   "source": [
    "### Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8caf30-86c0-4638-9b6e-4d5a58b62bd5",
   "metadata": {},
   "source": [
    "#### Z-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0e576d4-415d-417b-b58f-b92d55bb8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839d4917-fe97-431c-806d-97037c2e8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "control_users = 30000\n",
    "treatment_users = 30000\n",
    "control_conversions = 1202\n",
    "treatment_conversions = 1298\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "alpha = 1 - confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee9dc02b-ac23-4570-b2ad-d7d146560dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "count = np.array([treatment_conversions, control_conversions])\n",
    "nobs = np.array([treatment_users, control_users])\n",
    "tstat, p_value = proportions_ztest(\n",
    "    count=count,\n",
    "    nobs=nobs,\n",
    "    alternative=alternative\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3c1fc15-a165-4cb6-b807-6fd3a3e125e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference is statistically significant, with a p-value = 0.0498.\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "if p_value <= alpha:\n",
    "    outcome = \"is\"\n",
    "else:\n",
    "    outcome = \"is not\"\n",
    "if round(p_value, 4) < 0.0001:\n",
    "    value = \"< 0.0001\"\n",
    "else:\n",
    "    value = f\"= {p_value:.4f}\"\n",
    "print(f\"The difference {outcome} statistically significant, with a p-value {value}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4627e9-f080-4bb6-b44d-e4642e049676",
   "metadata": {},
   "source": [
    "#### Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21e8dc77-73d8-4799-9bb6-35b474272818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ef92b47-ecde-4900-b878-262cabef8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "control_users = 30000\n",
    "treatment_users = 30000\n",
    "control_conversions = 1202\n",
    "treatment_conversions = 1298\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "alpha = 1 - confidence\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fe84716-c180-469c-9f95-b4444ba4838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the observed difference\n",
    "control_proportion = control_conversions / control_users\n",
    "treatment_proportion = treatment_conversions / treatment_users\n",
    "observed_diff = treatment_proportion - control_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b01b9748-ce80-4660-8754-ba2447815ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pool to draw the samples\n",
    "control_no_conversions = control_users - control_conversions\n",
    "treatment_no_conversions = treatment_users - treatment_conversions\n",
    "conversion = [0] * (control_no_conversions + treatment_no_conversions)\n",
    "conversion.extend([1] * (control_conversions + treatment_conversions))\n",
    "conversion = pd.Series(conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "337393bb-9693-489a-9250-8687ae7424b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the permutation function\n",
    "def permutation(x, nC, nT):\n",
    "    n = nC + nT\n",
    "    idx_T = set(random.sample(range(n), nT))\n",
    "    idx_C = set(range(n)) - idx_T\n",
    "    return x.loc[list(idx_T)].mean() - x.loc[list(idx_C)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23372114-1c2e-40a1-b3bb-c151fd16af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the permutation test\n",
    "random.seed(0)\n",
    "perm_diffs = []\n",
    "for _ in range(iterations):\n",
    "    perm_diffs.append(\n",
    "        permutation(\n",
    "            conversion,\n",
    "            control_users,\n",
    "            treatment_users\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b868ce1b-3e26-496b-bdd6-727a02fc8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "if alternative == \"smaller\":\n",
    "    p_value = np.mean([diff <= observed_diff for diff in perm_diffs])\n",
    "elif alternative == \"larger\":\n",
    "    p_value = np.mean([diff >= observed_diff for diff in perm_diffs])\n",
    "elif alternative == \"two-sided\":\n",
    "    p_value = np.mean([abs(diff) >= abs(observed_diff) for diff in perm_diffs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42d1bff2-ca59-491f-9814-6791338da259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference is not statistically significant, with a p-value = 0.0640.\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "if p_value <= alpha:\n",
    "    outcome = \"is\"\n",
    "else:\n",
    "    outcome = \"is not\"\n",
    "if round(p_value, 4) < 0.0001:\n",
    "    value = \"< 0.0001\"\n",
    "else:\n",
    "    value = f\"= {p_value:.4f}\"\n",
    "print(f\"The difference {outcome} statistically significant, with a p-value {value}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca68b0b9-cafa-4340-88ec-5898d4d0e7c5",
   "metadata": {},
   "source": [
    "### Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dad471-e126-4e89-923b-063cc737f1bc",
   "metadata": {},
   "source": [
    "#### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b159795-0771-419a-8c5d-656a0083dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.weightstats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2047d1a5-a2ac-4276-9c3b-a2647b732dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"datasets/statistical_significance/dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87f8f892-bef0-488d-a428-18d5f4a9c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "alpha = 1 - confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e2bf4dd-c899-4ca3-b084-1d789aa28167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the observed difference\n",
    "control_mean = df[df[\"Group\"] == \"Control\"][\"Measurement\"].mean()\n",
    "treatment_mean = df[df[\"Group\"] == \"Treatment\"][\"Measurement\"].mean()\n",
    "observed_diff = treatment_mean - control_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9435c13-a4c3-4911-a036-e25a3ba6b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the control and treatment measurements\n",
    "control_measurements = df[df[\"Group\"] == \"Control\"][\"Measurement\"]\n",
    "treatment_measurements = df[df[\"Group\"] == \"Treatment\"][\"Measurement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f756ba4-1954-4ee6-ac95-f62d328a1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "tstat, p_value, dof = ttest_ind(\n",
    "    treatment_measurements,\n",
    "    control_measurements,\n",
    "    alternative=alternative\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04e66e2a-08b7-431b-84d1-c9d3bc05e2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference is statistically significant, with a p-value = 0.0271.\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "if p_value <= alpha:\n",
    "    outcome = \"is\"\n",
    "else:\n",
    "    outcome = \"is not\"\n",
    "if round(p_value, 4) < 0.0001:\n",
    "    value = \"< 0.0001\"\n",
    "else:\n",
    "    value = f\"= {p_value:.4f}\"\n",
    "print(f\"The difference {outcome} statistically significant, with a p-value {value}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71051142-a323-45f9-a45a-e22ae5c1f7ff",
   "metadata": {},
   "source": [
    "#### Z-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ad824e8-f8d8-4f33-bbf6-5d0c9c0dae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.weightstats import ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51652916-af27-4e10-9ab0-c8e29624a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"datasets/statistical_significance/dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db523089-ad5d-4654-b8cf-f9e3a67078df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "alpha = 1 - confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2c9cc30-e9e1-4f51-9d41-a2d8ab4eab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the observed difference\n",
    "control_mean = df[df[\"Group\"] == \"Control\"][\"Measurement\"].mean()\n",
    "treatment_mean = df[df[\"Group\"] == \"Treatment\"][\"Measurement\"].mean()\n",
    "observed_diff = treatment_mean - control_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d08e37a-d5d9-4818-9e3e-241080e0ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the control and treatment measurements\n",
    "control_measurements = df[df[\"Group\"] == \"Control\"][\"Measurement\"]\n",
    "treatment_measurements = df[df[\"Group\"] == \"Treatment\"][\"Measurement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "993ac39c-55e5-4780-89eb-d97110697bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "tstat, p_value = ztest(\n",
    "    treatment_measurements,\n",
    "    control_measurements,\n",
    "    alternative=alternative\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbb04e2b-c541-457e-a819-73e38d1b9cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference is statistically significant, with a p-value = 0.0260.\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "if p_value <= alpha:\n",
    "    outcome = \"is\"\n",
    "else:\n",
    "    outcome = \"is not\"\n",
    "if round(p_value, 4) < 0.0001:\n",
    "    value = \"< 0.0001\"\n",
    "else:\n",
    "    value = f\"= {p_value:.4f}\"\n",
    "print(f\"The difference {outcome} statistically significant, with a p-value {value}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d8094-a4bb-44aa-b40a-7d8196030a73",
   "metadata": {},
   "source": [
    "#### Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b48ee988-fd80-4060-ad59-31cf5e03076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e0d3cc6-e73c-44a9-92d6-6d3b07a6a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"datasets/statistical_significance/dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "650698db-88ce-4474-8b7b-95fefa125eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "alternative = \"two-sided\"\n",
    "confidence = 0.95\n",
    "alpha = 1 - confidence\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af077901-7cb5-489e-b02f-fc48ad36eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the measurements and count the users\n",
    "measurements = df[\"Measurement\"]\n",
    "control_users = df[df[\"Group\"] == \"Control\"].shape[0]\n",
    "treatment_users = df[df[\"Group\"] == \"Treatment\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e9c4fc1-7242-416c-b185-0216f0277fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the observed difference\n",
    "control_mean = df[df[\"Group\"] == \"Control\"][\"Measurement\"].mean()\n",
    "treatment_mean = df[df[\"Group\"] == \"Treatment\"][\"Measurement\"].mean()\n",
    "observed_diff = treatment_mean - control_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b7f411d-c639-4fbf-a8d3-b4f164eee473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the permutation function\n",
    "def permutation(x, nC, nT):\n",
    "    n = nC + nT\n",
    "    idx_C = set(random.sample(range(n), nT))\n",
    "    idx_T = set(range(n)) - idx_C\n",
    "    return x.loc[list(idx_T)].mean() - x.loc[list(idx_C)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b326520d-f351-4f77-9309-012914b92189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the permutation test\n",
    "random.seed(0)\n",
    "perm_diffs = []\n",
    "for _ in range(iterations):\n",
    "    perm_diffs.append(\n",
    "        permutation(\n",
    "            measurements,\n",
    "            control_users,\n",
    "            treatment_users\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c581ef4-dc57-42c8-9939-8544e0e019a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value\n",
    "if alternative == \"smaller\":\n",
    "    p_value = np.mean([diff <= observed_diff for diff in perm_diffs])\n",
    "elif alternative == \"larger\":\n",
    "    p_value = np.mean([diff >= observed_diff for diff in perm_diffs])\n",
    "elif alternative == \"two-sided\":\n",
    "    p_value = np.mean([abs(diff) >= abs(observed_diff) for diff in perm_diffs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a041ed7b-9309-40a5-975e-afee3eec234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference is statistically significant, with a p-value = 0.0290.\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "if p_value <= alpha:\n",
    "    outcome = \"is\"\n",
    "else:\n",
    "    outcome = \"is not\"\n",
    "if round(p_value, 4) < 0.0001:\n",
    "    value = \"< 0.0001\"\n",
    "else:\n",
    "    value = f\"= {p_value:.4f}\"\n",
    "print(f\"The difference {outcome} statistically significant, with a p-value {value}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
